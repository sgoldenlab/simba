{
  "weights_path": "Absolute path to the YOLO pose model (.pt, .onnx, etc.) you want to run. Choose the file exported from training.",
  "save_dir": "Folder where SimBA will write the tracked pose CSV files. Leave blank to keep results in memory only.",
  "bp_config_csv_path": "CSV listing body-part names in the order expected by the model. Each name on its own line (e.g., Nose, LeftEar, ...).",
  "batch_dropdown": "Number of frames processed at once. Larger batches speed up inference but require more GPU RAM.",
  "verbose_dropdown": "Toggle console printouts for progress and timings. Keep TRUE while tuning, FALSE for quiet runs.",
  "workers_dropdown": "How many CPU worker threads to use for pre/post-processing. Set <= available cores.",
  "format_dropdown": "Export/serialization format. Training: export the trained model to this format after training (None = PyTorch .pt only). Inference: match the format of your weights file, or None to auto-detect from file extension. Options: onnx, engine, torchscript, onnxsimplify, coreml, openvino, pb, tf, tflite, torch.",
  "img_size_dropdown": "Resize shorter image side to this many pixels before inference. Larger sizes improve accuracy but slow down processing.",
  "devices_dropdown": "Compute device to run on. Select CUDA device ID for GPU or CPU.",
  "interpolate_dropdown": "Fill missing detections by interpolating coordinates over time. Recommended for cleaner trajectories.",
  "stream_dropdown": "Enable streaming inference which reads frames sequentially (lower memory footprint). Disable for random seeking.",
  "threshold_dropdown": "Minimum detection confidence to keep. Lower values detect more poses but introduce more false positives.",
  "iou_dropdown": "Minimum bounding-box overlap required to keep the same track between frames. Higher values demand tighter alignment.",
  "max_tracks_dropdown": "Maximum number of simultaneous object tracks the model can follow in each frame.",
  "max_track_per_id_dropdown": "Cap on how many concurrent tracks a single class ID (e.g., a specific animal) can occupy.",
  "smoothing_dropdown": "Apply temporal smoothing over this many milliseconds to reduce jitter in keypoint trajectories.",
  "recursive_dropdown": "If False, only analyses videos in the immediate parent folder. If True, searches all sub-directories as well.",
  "CPU_ROI_DESCRIPTIVE_ANALYSIS": "If few videos (<1000), consider single CPU. If more videos (>1000), consider higher CPU count for acceptable speed.",
  "CPU_TIMEBINS_MOVEMENT": "If few videos (<1000), consider single CPU. If more videos (>1000), consider higher CPU count for acceptable speed.",
  "TIMEBINS_MOVEMENT_NUMBER_OF_ANIMALS": "How many animals to analyze. This controls how many body-part selectors are shown.",
  "TIMEBINS_MOVEMENT_BODY_PART": "Body-part used to track movement for this animal (for example, Center or Nose).",
  "TIMEBINS_MOVEMENT_TIME_BIN_SIZE": "Length of each time bin in seconds (for example, 60 = one-minute bins).",
  "TIMEBINS_MOVEMENT_CREATE_PLOTS": "Create line plots of movement results across time bins.",
  "TIMEBINS_MOVEMENT_DISTANCE": "Include distance traveled (cm) for each time bin.",
  "TIMEBINS_MOVEMENT_VELOCITY": "Include average velocity (cm/s) for each time bin.",
  "TIMEBINS_MOVEMENT_TRANSPOSE": "Save output in wide format (time bins as columns) instead of long format.",
  "TIMEBINS_MOVEMENT_INCLUDE_TIMESTAMPS": "Include start and end timestamps for each time bin in the output.",
  "MOVEMENT_PROBABILITY_THRESHOLD": "Pose-confidence cutoff (0.0-1.0). Frames below this value are ignored.",
  "MOVEMENT_DISTANCE": "If checked, calculates the total distance traveled (in centimeters) for each animal throughout the entire video. Distance is measured as cumulative path length of the selected body-part.",
  "MOVEMENT_VELOCITY": "If checked, calculates the average velocity (in cm/s) for each animal throughout the entire video. Velocity is computed as distance divided by time.",
  "MOVEMENT_TRANSPOSE": "If checked, transposes the output CSV so that videos are in rows and animal/body-part/measurement combinations are in columns. Default: each row is a video-animal-bodypart-measurement combination.",
  "DISTANCE_ANALYSIS_NUMBER_OF_PAIRS": "How many body-part pairs to analyze. SimBA creates one BODY-PART 1 / BODY-PART 2 row per pair.",
  "DISTANCE_ANALYSIS_BODY_PART": "Pick one body-part for this side of the pair. Each row must use two different body-parts.",
  "DISTANCE_ANALYSIS_BP_THRESHOLD": "Pose confidence cutoff (0.0-1.0). Frames where either body-part is below this value are ignored for this pair.",
  "DISTANCE_ANALYSIS_DISTANCE_FILTER": "Enable an additional distance-threshold analysis for each pair. SimBA then reports time spent below and above the threshold.",
  "DISTANCE_ANALYSIS_DISTANCE_THRESHOLD": "Distance threshold in millimeters. Mean/median are calculated from distances below this value, and SimBA also reports total time below vs above it.",
  "DISTANCE_ANALYSIS_METRICS": "Choose which summary metrics to output for each pair (mean and/or median distance). Values are written in millimeters.",
  "DISTANCE_ANALYSIS_TRANSPOSE": "If checked, output is wide format (one row per video). If unchecked, output is long format (one row per video/pair/metric).",
  "DISTANCE_TIMEBINS_BP_THRESHOLD": "Pose confidence cutoff (0.0-1.0). Within each time bin, frames where either body-part is below this value are excluded.",
  "DISTANCE_TIMEBINS_TIME_BIN_SIZE": "Time-bin length in seconds (must be > 0). Distances are summarized separately for each bin.",
  "DISTANCE_TIMEBINS_METRICS": "Choose which per-bin metrics to output (mean, median, variance). Distance values are computed in millimeters.",
  "DISTANCE_TIMEBINS_TRANSPOSE": "If checked, output is transposed so each metric forms columns across time-bin numbers. If unchecked, each row represents one video/bin/pair/metric result.",
  "TIMEBINS_CLF_TIME_BIN_SIZE": "Duration of each time bin in seconds. Video is divided into equal segments and classification metrics calculated per bin.",
  "TIMEBINS_CLF_FIRST_OCCURRENCE": "If checked, calculates the time (in seconds) when the behavior first occurs within each time bin.",
  "TIMEBINS_CLF_EVENT_COUNT": "If checked, counts how many times the behavior occurs within each time bin.",
  "TIMEBINS_CLF_TOTAL_EVENT_DURATION": "If checked, calculates the total duration (in seconds) that the behavior occurs within each time bin.",
  "TIMEBINS_CLF_MEAN_EVENT_DURATION": "If checked, calculates the average duration (in seconds) of each behavior bout within each time bin.",
  "TIMEBINS_CLF_MEDIAN_EVENT_DURATION": "If checked, calculates the median duration (in seconds) of each behavior bout within each time bin.",
  "TIMEBINS_CLF_MEAN_INTERVAL_DURATION": "If checked, calculates the average time (in seconds) between behavior events within each time bin.",
  "TIMEBINS_CLF_MEDIAN_INTERVAL_DURATION": "If checked, calculates the median time (in seconds) between behavior events within each time bin.",
  "TIMEBINS_CLF_CLASSIFIER": "Select which classifier(s) to analyze. At least one classifier must be selected.",
  "TIMEBINS_CLF_TRANSPOSE": "If checked, transposes output so each video is one row and classifier-timebin-measurement combinations are columns. Default: each row is a video-timebin-classifier-measurement combination.",
  "TIMEBINS_CLF_INCLUDE_TIME": "If checked, adds timestamp columns (HH:MM:SS format) showing start and end time of each time bin.",
  "CLF_DESC_FIRST_OCCURRENCE": "If checked, calculates the time (in seconds) when the behavior first occurs in each video.",
  "CLF_DESC_EVENT_COUNT": "If checked, counts the total number of behavior bouts (events) in each video.",
  "CLF_DESC_TOTAL_EVENT_DURATION": "If checked, calculates the total duration (in seconds) that the behavior occurs across all bouts in each video.",
  "CLF_DESC_TOTAL_EVENT_DURATION_PCT": "If checked, calculates the total duration of the behavior as a percentage of the video (session) length. Useful for comparing across videos of different lengths.",
  "CLF_DESC_MEAN_EVENT_DURATION": "If checked, calculates the average duration (in seconds) of each behavior bout in each video.",
  "CLF_DESC_MEDIAN_EVENT_DURATION": "If checked, calculates the median duration (in seconds) of each behavior bout in each video.",
  "CLF_DESC_MEAN_INTERVAL_DURATION": "If checked, calculates the average time (in seconds) between behavior events in each video.",
  "CLF_DESC_MEDIAN_INTERVAL_DURATION": "If checked, calculates the median time (in seconds) between behavior events in each video.",
  "CLF_DESC_CLASSIFIER": "Select which classifier(s) to analyze. At least one classifier must be selected.",
  "CLF_DESC_DETAILED_BOUT_DATA": "If checked, creates a separate CSV file with detailed information for each individual behavior bout, including start time, end time, and duration.",
  "CLF_DESC_FRAME_COUNT": "If checked, includes the total number of frames in each video as a metadata column in the output.",
  "CLF_DESC_VIDEO_LENGTH": "If checked, includes the video length in seconds as a metadata column in the output.",
  "CLF_DESC_TRANSPOSE": "If checked, transposes output so each video is one row and classifier-measurement combinations are columns. Default: each row is a video-classifier-measurement combination.",
  "ROI_CLF_ROI": "Select which ROI(s) to analyze. At least one ROI must be selected. Analysis calculates behavior metrics within each selected ROI.",
  "ROI_CLF_CLASSIFIER": "Select which classifier(s) to analyze. At least one classifier must be selected. Behavior metrics are calculated for each selected classifier within ROIs.",
  "ROI_CLF_BODY_PART": "Select which body-part(s) to use for determining animal location within ROIs. At least one body-part must be selected. Typically use center of mass or prominent body-part.",
  "ROI_CLF_TOTAL_TIME": "If checked, calculates the total duration (in seconds) that the behavior occurs within each ROI. Sums all time the animal spends performing the behavior inside the ROI.",
  "ROI_CLF_STARTED_BOUTS": "If checked, counts how many behavior bouts STARTED within each ROI. A bout starts when the behavior begins while the animal is inside the ROI.",
  "ROI_CLF_ENDED_BOUTS": "If checked, counts how many behavior bouts ENDED within each ROI. A bout ends when the behavior stops while the animal is inside the ROI.",
  "ROI_CLF_DETAILED_BOUTS": "If checked, creates a detailed CSV table listing each individual behavior bout within ROIs, including start time, end time, duration, and which ROI it occurred in.",
  "ROI_CLF_TRANSPOSE": "If checked, transposes output so each video is one row and classifier-ROI-bodypart-measurement combinations are columns. Default: each row is a video-classifier-ROI-bodypart-measurement combination.",
  "HEATMAP_LOCATION_PALETTE": "Color scheme for the heatmap. Different palettes (e.g., jet, magma, viridis) show intensity variations differently. Choose based on visual preference and data contrast needs.",
  "HEATMAP_LOCATION_SHADING": "Shading style for heatmap visualization. 'gouraud' creates smooth gradients between bins, 'flat' uses solid colors per bin. Gouraud is smoother but may blur boundaries.",
  "HEATMAP_LOCATION_BODY_PART": "Body-part to track for location heatmap. The heatmap shows where this body-part spends time. Typically use center of mass (e.g., 'Center') or a prominent body-part like 'Nose'.",
  "HEATMAP_LOCATION_MAX_TIME_SCALE": "Maximum time scale in seconds for color mapping. Values >= this duration get the maximum color intensity. 'Auto-compute' uses the maximum time found in the data.",
  "HEATMAP_LOCATION_BIN_SIZE": "Size of each spatial bin in millimeters. Smaller bins (e.g., 50mm) create finer detail but more bins. Larger bins (e.g., 100mm) create coarser but smoother heatmaps.",
  "HEATMAP_LOCATION_CPU_CORES": "Number of CPU cores to use for processing. Higher values speed up processing for multiple videos but use more memory. Recommended: half of available cores.",
  "HEATMAP_LOCATION_CREATE_FRAMES": "If checked, saves individual frame images showing the heatmap at each frame. Creates one image file per frame in the output directory.",
  "HEATMAP_LOCATION_CREATE_VIDEOS": "If checked, creates video files showing the heatmap animated over time. The heatmap intensity grows as the animal spends more time in each location.",
  "HEATMAP_LOCATION_CREATE_LAST_FRAME": "If checked, saves a single image showing the cumulative heatmap up to the final frame. This shows total time spent in each location (default: enabled).",
  "HEATMAP_LOCATION_SINGLE_VIDEO": "Select which video to create a location heatmap for. Only one video will be processed when using the 'Create single video' button.",
  "HEATMAP_LOCATION_SHOW_LEGEND": "Show or hide the color bar that explains what the heatmap colors mean (seconds spent in each area).",
  "HEATMAP_LOCATION_MIN_SECONDS": "Hide bins with very low occupancy. Bins with time below this value appear empty. Use NONE to show all bins.",
  "HEATMAP_LOCATION_BACKGROUND": "What to put behind the heatmap. NONE = plain heatmap. VIDEO = overlay on the video. VIDEO FRAME = overlay on a single chosen frame.",
  "HEATMAP_LOCATION_LINE_COLOR": "Color of the grid lines between heatmap bins. NONE = no grid lines.",
  "HEATMAP_LOCATION_PLOT_TIME_PERIOD": "If checked, only the time segment between START TIME and END TIME is included in the heatmap.",
  "HEATMAP_LOCATION_START_TIME": "Start of the time segment (HH:MM:SS). Only used when Plot select time-period is checked.",
  "HEATMAP_LOCATION_END_TIME": "End of the time segment (HH:MM:SS). Must be after start time.",
  "HEATMAP_LOCATION_OPACITY": "How transparent the heatmap is over the video. Lower = more transparent; higher = more opaque.",
  "HEATMAP_LOCATION_SHOW_KEYPOINT": "Draw the tracked body-part position as a dot on each frame of the heatmap.",
  "HEATMAP_LOCATION_VIDEO_FRAME": "Frame number to use as the static background when HEATMAP BACKGROUND is set to VIDEO FRAME. Frame 1 is the first frame.",
  "HEATMAP_CLF_PALETTE": "Color scheme for the heatmap (e.g. jet, magma, viridis).",
  "HEATMAP_CLF_SHADING": "Smoothing between bins. Gouraud = smooth gradients; flat = solid colors per bin.",
  "HEATMAP_CLF_CLASSIFIER": "Which behavior to show. The heatmap displays where this behavior occurs in the arena over time.",
  "HEATMAP_CLF_BODY_PART": "Body-part used to pinpoint location. When the classifier detects the behavior, SimBA records where this body-part is. The heatmap shows where in the arena the behavior tends to occur.",
  "HEATMAP_CLF_MAX_TIME_SCALE": "Maximum seconds for the color scale. Values at or above this get the brightest color. AUTO = use max in your data.",
  "HEATMAP_CLF_BIN_SIZE": "Size of each spatial bin in mm. Smaller = finer detail; larger = smoother heatmap.",
  "HEATMAP_CLF_MIN_SECONDS": "Hide bins with very low behavior duration. Bins below this (seconds) appear empty. NONE = show all bins.",
  "HEATMAP_CLF_SHOW_LEGEND": "Show or hide the color bar that explains the heatmap scale (seconds of behavior per location).",
  "HEATMAP_CLF_CPU_CORES": "Number of CPU cores for processing. More cores = faster.",
  "HEATMAP_CLF_BACKGROUND": "What to put behind the heatmap. NONE = plain. VIDEO = overlay on full video. VIDEO FRAME = overlay on one chosen frame.",
  "HEATMAP_CLF_SINGLE_VIDEO": "Select which video to create a classifier heatmap for. Requires classifier results in machine_results.",
  "HEATMAP_CLF_OPACITY": "Heatmap transparency as percentage (5 = very transparent, 100 = fully opaque). Used when a video or frame background is selected.",
  "HEATMAP_CLF_SHOW_KEYPOINT": "If TRUE, draws a dot showing the body-part position on each frame of the heatmap video.",
  "HEATMAP_CLF_FRAME_NUMBER": "Which video frame to use as the static background when HEATMAP BACKGROUND is VIDEO FRAME. 0 = first frame.",
  "HEATMAP_CLF_CREATE_FRAMES": "If checked, saves a separate image for each frame of the heatmap video.",
  "HEATMAP_CLF_CREATE_VIDEOS": "If checked, creates a video showing the heatmap building up over time.",
  "HEATMAP_CLF_CREATE_LAST_FRAME": "If checked, saves a single image of the final cumulative heatmap (default: on).",
  "DIRECTING_ANIMALS_LEFT_EAR": "Body-part used for the left ear. SimBA uses left ear, right ear, and nose to estimate where each animal is looking.",
  "DIRECTING_ANIMALS_RIGHT_EAR": "Body-part used for the right ear. Must be different from left ear and nose.",
  "DIRECTING_ANIMALS_NOSE": "Body-part used for the nose. Must be different from left and right ear.",
  "DIRECTING_ANIMALS_SHOW_POSE": "If TRUE, draws circles at each body-part on every frame so you can see the tracked pose.",
  "DIRECTING_ANIMALS_HIGHLIGHT_ENDPOINTS": "If TRUE, draws a circle where each direction line ends (the body-part the animal is looking at).",
  "DIRECTING_ANIMALS_SHOW_NAMES": "If TRUE, displays each animal's name next to their pose on the video.",
  "DIRECTING_ANIMALS_DIRECTION_COLOR": "Color of the lines showing gaze direction. Choose 'random' to assign different colors per animal.",
  "DIRECTING_ANIMALS_POSE_SIZE": "Size of the pose circles in pixels. AUTO scales based on video resolution.",
  "DIRECTING_ANIMALS_LINE_THICKNESS": "Thickness of the direction lines in pixels. AUTO scales based on video resolution.",
  "DIRECTING_ANIMALS_LINE_OPACITY": "How solid the direction lines appear (0.1 = faint, 1.0 = fully opaque).",
  "DIRECTING_ANIMALS_CPU_CORES": "Number of CPU cores used for processing. More cores = faster, but uses more memory.",
  "DIRECTING_ANIMALS_SINGLE_VIDEO": "Select which video to create a directionality visualization for.",
  "SHOW_ANIMAL_BBOX": "Display rectangle bounding boxes encompassing all animal keypoints",
  "BORDER_BG_COLOR": "The color of the border image on which data is printed",
  "USE_GPU": "If GPU available and selected, then potentially faster processing times.",
  "OUPUT_VIDEO_QUALITY": "Higher values produce larger, higher quality, videos. Lower values produce smaller, lower quality videos. \nScale not linear. Avoid values above 80 if possible. 60 generally works well.",
  "OUTPUT_VIDEO_QUALITY": "Higher values produce larger, higher quality, videos. Lower values produce smaller, lower quality videos. \nScale not linear. Avoid values above 80 if possible. 60 generally works well.",
  "VIDEO_SPEED": "2 doubles the speed, while 0.5 halves the speed.",
  "VIDEO_CODEC": "Video codec to use for encoding. Common options include libx264 (CPU, widely compatible), h264_nvenc (NVIDIA GPU), libx265 (CPU, better compression), and libvpx-vp9 (CPU, web optimized). Codec availability depends on your FFmpeg installation.",
  "RESOLUTION_CONCAT": "If the two videos have different resolutions, which resolution should be retained in each video of the concatenated results?",
  "LOCATION_FRAME_COUNT": "The location in the video where the \n frame count is positioned.",
  "ROTATE_FILL_COLOR": "When video is rotated, there may be empty space not \n covered by the video. What color should this space have?",
  "VIDEO_DIR": "Directory containing videos.",
  "SAVE_DIR": "Directory where to save results.",
  "CONCAT_HEIGHT": "If join involves aligning videos horizontally, this values \nwill be used to ensure videos have the same height. ",
  "CONCAT_WIDTH": "If join involves aligning videos vertically, this values \nwill be used to ensure videos have the same width. ",
  "CONCAT_RES_HEADER": "When stacking videos horizontally and/or vertically, \n the videos need to be same height and/or width. Here, \n select what resolution to use.",
  "EGOCENTRIC_DATA_DIR": "Folder containing pose-estimation CSV data.\n Can be sub-directory in 'project_folder/csv' folder.\n Should contain same file names as the VIDEO files",
  "EGOCENTRIC_VIDEO_DIR": "Folder containing videos.\n Should contain same file names as the DATA files.",
  "EGOCENTRIC_ANCHOR": "This body-part will be placed in the center of the video",
  "EGOCENTRIC_DIRECTION_ANCHOR": "This body-part will be placed at N degrees relative to the anchor",
  "EGOCENTRIC_DIRECTION": "The anchor body-part will always be placed at these degrees relative to the center anchor",
  "CORE_COUNT": "Higher core counts speeds up processing but may require more RAM memory",
  "CLAHE_CLIP_LIMIT": "CLAHE contrast limit. Higher values allow more contrast enhancement per tile; lower values (e.g. 2–4) keep enhancement mild and reduce noise. Typical range 2–10.",
  "CLAHE_TILE_HEIGHT": "Height of each CLAHE tile in pixels. The image is split into a grid; each tile is equalized separately. Larger tiles (e.g. 32) give smoother, less localized contrast; smaller (e.g. 8) enhance local detail but can amplify noise.",
  "CLAHE_TILE_WIDTH": "Width of each CLAHE tile in pixels. Should match tile height for square tiles. The image is split into a grid; each tile is equalized separately. Use with TILE SIZE (HEIGHT) to control how local the contrast enhancement is.",
  "KLEINBERG_SIGMA": "Higher values (e.g., 2-3) produce fewer but longer bursts; lower values (e.g., 1.1-1.5) detect more frequent, shorter bursts. Must be > 1.01",
  "KLEINBERG_GAMMA": "Higher values (e.g., 0.5-1.0) reduce total burst count by making downward transitions costly; lower values (e.g., 0.1-0.3) allow more flexible state changes",
  "KLEINBERG_HIERARCHY": "Hierarchy level to extract bursts from (0=lowest, higher=more selective).\n Level 0 captures all bursts; level 1-2 typically filters noise; level 3+ selects only the most prominent, sustained bursts.\nHigher levels yield fewer but more confident detections",
  "KLEINBERG_HIERARCHY_SEARCH": "If True, searches for target hierarchy level within detected burst periods,\n falling back to lower levels if target not found. If False, extracts only bursts at the exact specified hierarchy level.\n Recommended when target hierarchy may be sparse.",
  "KLEINBERG_SAVE_ORIGINALS": "If True, saves the original data in a new sub-directory of \nthe project_folder/csv/machine_results directory",
  "yolo_map_path": "Path to the YOLO dataset YAML file. Defines class names, paths to train/val images and labels, and number of keypoints.",
  "yolo_initial_weights_path": "Optional path to pretrained weights (.pt) to start training from (e.g. yolo11n-pose.pt). Leave blank to train from scratch.",
  "epochs_dropdown": "Number of training epochs. More epochs can improve accuracy but increase overfitting risk and training time.",
  "plots_dropdown": "If TRUE, generate and save training curves (loss, mAP, etc.) in the save directory.",
  "patience_dropdown": "Early-stopping patience: training stops if validation metric does not improve for this many epochs.",
  "simba2yolo_config": "Path to the SimBA project configuration file (.ini). Defines project paths, body-parts, and animals.",
  "simba2yolo_train_size": "Percentage of sampled frames to use for the YOLO training set. The remainder is used for validation. E.g. 70 means 70% train, 30% val.",
  "simba2yolo_padding": "Extra margin (as a fraction of image size) added around the keypoint bounding box. Use a small value (e.g. 0.05–0.2) if the tight box cuts off body parts or you want more context in each crop; None or 0 = no padding.",
  "simba2yolo_sample_size": "Maximum number of frames to sample per video for creating YOLO images and labels. Higher values give more data but increase processing time.",
  "simba2yolo_grey": "If TRUE, extracted video frames are saved in greyscale. If FALSE, frames are saved in color.",
  "simba2yolo_clahe": "If TRUE, apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to frames before saving. Can improve keypoint visibility in low-contrast videos.",
  "yolo_plot_line_thickness": "Thickness of the lines drawn between keypoints (skeleton). AUTO lets the plotter choose based on video size; or set 1–20 pixels.",
  "yolo_plot_circle_size": "Radius of the circles drawn at each keypoint. AUTO lets the plotter choose based on video size; or set 1–20 pixels.",
  "yolo_plot_tracks": "If TRUE, draw trajectory paths (tracks) for each detected instance over time. If FALSE, draw only keypoints and skeleton per frame.",
  "yolo_plot_data_path": "Path to a single YOLO pose result CSV (output from YOLO pose inference). Must match the video you select.",
  "yolo_plot_video_path": "Path to the video file to overlay pose results onto. Filename should match the data CSV (without extension).",
  "yolo_plot_data_dir": "Directory containing YOLO pose result CSV files. Used for batch plotting; each CSV is matched to a video of the same name in the video directory.",
  "SLEAP_DATA_DIR": "Directory containing SLEAP CSV prediction files. Each CSV should match a video filename (without extension).",
  "ANIMAL_COUNT": "Number of animals (tracks) in the videos. Used to name classes (e.g. animal_1, animal_2) in the YOLO dataset.",
  "sleap_remove_animal_ids": "If TRUE, merge all tracks into a single identity (animal_1). Use when animal IDs are not meaningful or for single-animal data.",
  "sleap_threshold": "Minimum SLEAP instance confidence (the instance.score column in the CSV). Only pose predictions with score ≥ this value are used when building the YOLO dataset. E.g. 90 means keep instances where instance.score ≥ 0.9; lower values include more frames but may add noisy predictions.",
  "SLEAP_SLP_DATA_DIR": "Directory containing SLEAP .SLP project/annotation files. Each .SLP file is converted to YOLO pose format.",
  "BATCH_CLIP_START_TIME": "Start time for clipping all videos. Use HH:MM:SS (e.g. 00:00:10). Click APPLY to copy this value to every video row.",
  "BATCH_CLIP_END_TIME": "End time for clipping all videos. Use HH:MM:SS (e.g. 00:01:30). Must be after start time. Click APPLY to copy this value to every video row.",
  "BATCH_DOWNSAMPLE_WIDTH": "Output width in pixels when downsampling all videos. Must be even. Click APPLY to copy to every video row.",
  "BATCH_DOWNSAMPLE_HEIGHT": "Output height in pixels when downsampling all videos. Must be even. Click APPLY to copy to every video row.",
  "BATCH_FPS": "Target frames per second for all videos. Click APPLY to copy this value to every video row.",
  "BATCH_APPLY_DOWNSAMPLE": "Tick to check the downsample box for all videos (all will be downsampled on execute). Untick to uncheck all. Set width and height in the DOWNSAMPLE VIDEOS panel, then click APPLY there to copy those values to every row.",
  "BATCH_APPLY_FPS": "Tick to enable FPS change for all videos.\nUntick to disable for all.\nSet FPS in CHANGE FPS panel, then APPLY there.",
  "BATCH_APPLY_GREYSCALE": "Tick to enable greyscale for all videos.\nUntick to disable for all.",
  "BATCH_APPLY_FRAME_COUNT": "Tick to superimpose frame numbers on all videos.\nUntick to disable for all.",
  "BATCH_APPLY_CLAHE": "Tick to apply CLAHE (contrast) to all videos.\nUntick to disable for all.",
  "BATCH_APPLY_CLIP": "Tick to enable clipping for all videos.\nUntick to disable for all.\nSet start/end in CLIP VIDEOS SETTING, then APPLY there.",
  "BLOB_THRESHOLD": "How strict the background subtraction is (1–100). Lower = more counts as animal; higher = only strong differences.\nClick APPLY to put this value in every video row.",
  "BLOB_SMOOTHING_TIME": "Smooth the animal's position over time (seconds). Reduces jitter. None = no smoothing.\nClick APPLY to put this value in every video row.",
  "BLOB_BUFFER": "Extra pixels drawn around the detected animal (padding).\nClick APPLY to put this value in every video row.",
  "BLOB_GAP_FILL_SIZE": "Filter size (as % of frame) that fills small holes in the animal mask. Helps merge broken blobs. None = off.\nClick APPLY to put this value in every video row.",
  "BLOB_NOISE_REMOVAL_SIZE": "Filter size (as % of frame) that removes small speckles from the mask. Reduces false detections. None = off.\nClick APPLY to put this value in every video row.",
  "BLOB_VERTICE_COUNT": "Number of points used to describe the blob shape. Higher = more detailed outline.",
  "BLOB_SAVE_BG_VIDEOS": "If on, save the background-subtracted videos to the output folder.",
  "BLOB_GAP_FILL_ITERATIONS": "How many times to run the gap-fill filter. More = stronger filling.",
  "BLOB_NOISE_REMOVAL_ITERATIONS": "How many times to run the noise-removal filter. More = stronger cleaning.",
  "BLOB_DUPLICATE_INCLUSION": "Copy the inclusion zones you drew for one video to all others. Pick the source video, then click APPLY.",
  "BLOB_BACKGROUND_DIRECTORY": "Folder with one background reference video per video to track. File names must match input videos.\nClick APPLY to fill the BACKGROUND REFERENCE column for all rows.",
  "BLOB_HEADER_VIDEO_NAME": "Input video filename for this row.",
  "BLOB_HEADER_BACKGROUND_REFERENCE": "Background reference video path for this video.",
  "BLOB_HEADER_THRESHOLD": "Background subtraction strictness (1–100) for this video.",
  "BLOB_HEADER_SMOOTHING_TIME": "Smoothing time (seconds) for this video. Reduces jitter.",
  "BLOB_HEADER_BUFFER": "Padding (pixels) around the detected animal for this video.",
  "BLOB_HEADER_GAP_FILL_SIZE": "Gap-fill filter size (% of frame) for this video.",
  "BLOB_HEADER_NOISE_REMOVAL_SIZE": "Noise-removal filter size (% of frame) for this video.",
  "BLOB_HEADER_INCLUSION_ZONES": "Draw regions where the animal must stay. Tracking is ignored outside these zones.",
  "BLOB_HEADER_QUICK_CHECK": "Preview blob tracking for this video with current settings.",
  "VIDEO_INFO_KNOWN_DISTANCE": "Real-world length in millimeters (e.g. of an object in the video).\nEnter a value, then click APPLY to fill the DISTANCE IN MM column for all videos.",
  "VIDEO_INFO_PIXEL_PER_MM": "Calibration: how many pixels equal one millimeter in the video.\nEnter a value, then click APPLY to fill the PIXELS PER MM column for all videos.",
  "VIDEO_INFO_HEADER_INDEX": "Row number for this video in the table.",
  "VIDEO_INFO_HEADER_VIDEO_NAME": "Name of the video file.",
  "VIDEO_INFO_HEADER_FPS": "Frames per second. Should match the actual video frame rate.",
  "VIDEO_INFO_HEADER_VIDEO_WIDTH": "Width of the video in pixels.",
  "VIDEO_INFO_HEADER_VIDEO_HEIGHT": "Height of the video in pixels.",
  "VIDEO_INFO_HEADER_FIND_DISTANCE": "Click the button in this column to draw a line in the video and compute pixels per mm from the known distance.",
  "VIDEO_INFO_HEADER_DISTANCE_IN_MM": "Real-world length in millimeters (e.g. of an object you can measure in the video). Used to calculate pixels per mm.",
  "VIDEO_INFO_HEADER_PIXELS_PER_MM": "Calibration for this video: how many pixels equal one millimeter. SimBA uses this to convert distances to real units.",
  "VIDEO_INFO_DUPLICATE_DISTANCE": "Copy the DISTANCE IN MM value from the first video (top row) to all other videos. Use when all videos share the same known distance.",
  "VIDEO_INFO_DUPLICATE_PX_PER_MM": "Copy the PIXELS PER MM value from the first video (top row) to all other videos. Use when all videos have the same calibration.",
  "POSE_VIZ_KEYPOINT_SIZE": "Size of the circles drawn at each body-part. AUTO lets SimBA choose; or pick 1–100 pixels.",
  "POSE_VIZ_VIDEO_SECTION": "How much of each video to draw poses on. ENTIRE VIDEO(S) = full video; or pick a length in seconds (e.g. first 30 sec).",
  "POSE_VIZ_CENTER_OF_MASS": "If on, draw a dot at the center of mass for each animal. Pick a color for the dot, or FALSE to hide.",
  "POSE_VIZ_NUMBER_OF_ANIMALS": "Number of animals in your pose data. Used to assign colors and options per animal.",
  "POSE_VIZ_ANIMAL_COLOR": "Color palette for this animal's keypoints and tracks. AUTO picks a default.",
  "POSE_VIZ_DATA_FILE": "Pick one pose CSV or Parquet file from project_folder/csv (or a subfolder). SimBA will create a video with poses drawn on it.",
  "POSE_VIZ_DATA_DIR": "Pick a folder of pose CSV/Parquet files (e.g. a subfolder of project_folder/csv). SimBA will create videos for all files in the folder.",
  "PATH_PLOT_MAX_PRIOR_LINES": "Maximum number of seconds of path history to display. ENTIRE VIDEO shows the full path. Lower values show only recent movement (e.g., last 10 seconds).",
  "PATH_PLOT_RESOLUTION": "Output image/video resolution. AUTO uses the original video resolution. Custom resolutions are in format WIDTH×HEIGHT (e.g., 1920×1080).",
  "PATH_PLOT_BACKGROUND": "Background color or video frame. Choose a solid color, or 'Video - static frame' to use a single video frame, or 'Video - moving frames' to overlay paths on the video.",
  "PATH_PLOT_LINE_WIDTH": "Thickness of the path lines in pixels. AUTO lets SimBA choose based on video size. Higher values make paths more visible but thicker.",
  "PATH_PLOT_FONT_SIZE": "Size of the animal name text (if shown). AUTO lets SimBA choose. Higher values make names more readable but larger.",
  "PATH_PLOT_FONT_THICKNESS": "Boldness of the animal name text. AUTO lets SimBA choose. Higher values make text bolder and more visible.",
  "PATH_PLOT_BG_OPACITY": "Transparency of the background when using video frames (0-100%). 100% = fully opaque, 10% = very transparent. Only applies when background is set to video frames.",
  "PATH_PLOT_CIRCLE_SIZE": "Size of the circle marker drawn at the end of each path. AUTO lets SimBA choose. Higher values make the endpoint more visible.",
  "PATH_PLOT_SHOW_ANIMAL_NAMES": "If TRUE, displays animal names next to the end of each path. Useful for identifying which path belongs to which animal.",
  "PATH_PLOT_NUMBER_OF_ANIMALS": "Number of animals to plot paths for. This determines how many body-part and color dropdowns appear below.",
  "PATH_PLOT_BODY_PART": "Body-part to track for this animal's path. Typically use the center of mass (e.g., 'Center') or a prominent body-part like 'Nose'.",
  "PATH_PLOT_ANIMAL_COLOR": "Color or palette for this animal's path. Named colors (e.g., Red, Blue) create a solid-colored path. Palettes (e.g., viridis, plasma) create a \ngradient where colors change along the path based on time (older points = one color, newer points = another).\nChoose CUSTOM to enter RGB values manually (e.g., 255,0,0 for red).",
  "PATH_PLOT_CUSTOM_RGB": "Custom RGB color values. Enter as three numbers separated by commas (e.g., 255,0,0 for red). Values range from 0-255 for each color.",
  "PATH_PLOT_START_TIME": "Start time for the path plot segment. Format: HH:MM:SS (e.g., 00:00:10). Only used when 'Plot ONLY defined time-segment' is checked.",
  "PATH_PLOT_END_TIME": "End time for the path plot segment. Format: HH:MM:SS (e.g., 00:01:30). Must be after start time. Only used when 'Plot ONLY defined time-segment' is checked.",
  "PATH_PLOT_STATIC_FRAME_INDEX": "Frame number to use as background when 'Video - static frame' is selected. Frame 1 is the first frame of the video.",
  "PATH_PLOT_CPU_CORE_COUNT": "Number of CPU cores to use for processing. Higher values speed up processing for multiple videos but use more memory. Recommended: 1/3 of available cores.",
  "PATH_PLOT_SINGLE_VIDEO": "Select which video to create a path plot for. Only one video will be processed when using the 'CREATE SINGLE VIDEO' button.",
  "PATH_PLOT_CLF_NAME": "Classifier to visualize on the path plot. Shows where this behavior occurred as colored markers along the path.",
  "PATH_PLOT_CLF_COLOR": "Color for the classification markers. Choose a color that contrasts well with the path color for visibility.",
  "PATH_PLOT_CLF_SIZE": "Size of the classification markers in pixels. Larger values make markers more visible but may obscure the path.",
  "PATH_PLOT_TIME_SEGMENT": "If checked, only plots the path for the time segment defined by START TIME and END TIME. Uncheck to plot the entire video duration.",
  "PATH_PLOT_INCLUDE_CLF_LOCATIONS": "If checked, displays markers on the path plot showing where classification behaviors occurred. Each classifier can have its own color and size. Requires classification data to be available.",
  "PATH_PLOT_INCLUDE_ROIS": "If checked, overlays ROI (Region of Interest) shapes on the path plot. Requires ROI definitions to exist in the project. If disabled, no ROI data was found.",
  "PATH_PLOT_CREATE_FRAMES": "If checked, saves individual frame images showing the path plot at each frame. Creates one image file per frame in the output directory.",
  "PATH_PLOT_CREATE_VIDEOS": "If checked, creates video files showing the path plot animated over time. The path grows frame by frame as the animal moves.",
  "PATH_PLOT_CREATE_LAST_FRAME": "If checked, saves a single image showing the complete path plot up to the final frame. This is the cumulative path visualization (default: enabled).",
  "SIMPLE_PATH_PLOT_VIDEO_PATH": "Path to the video file. Used to get video dimensions and frame rate. The video file is not modified, only its metadata is read.",
  "SIMPLE_PATH_PLOT_DATA_PATH": "Path to pose estimation data file in H5 or CSV format. Must contain X and Y coordinates for the selected body-part. File should have columns like 'BodyPartName_x' and 'BodyPartName_y'.",
  "SIMPLE_PATH_PLOT_BODY_PART": "Name of the body-part to plot. Must match exactly the body-part name in your data file (without _x or _y suffix). For example, if your data has 'Nose_x' and 'Nose_y', enter 'Nose'.",
  "SIMPLE_PATH_PLOT_BACKGROUND_COLOR": "Background color for the path plot. Choose a color that contrasts well with your line color for visibility. White is a common choice.",
  "SIMPLE_PATH_PLOT_LINE_COLOR": "Color of the path line showing animal movement. Choose a color that contrasts with the background. Red is a common choice.",
  "SIMPLE_PATH_PLOT_LINE_THICKNESS": "Thickness of the path line in pixels (1-10). Higher values make the path more visible but thicker. Lower values create thinner, more precise lines.",
  "SIMPLE_PATH_PLOT_CIRCLE_SIZE": "Size of the circle marker at the end of the path in pixels (1-10). Higher values make the endpoint more visible. Lower values create smaller, less obtrusive markers.",
  "SIMPLE_PATH_PLOT_LAST_FRAME_ONLY": "If TRUE, creates only a single PNG image showing the complete cumulative path. If FALSE, creates a video showing the path growing frame-by-frame over time.",
  "ROI_TRACKING_SHOW_POSE": "If TRUE, displays body-part locations as colored circles on the video frames. If FALSE, only ROI shapes and statistics are shown without pose markers.",
  "ROI_TRACKING_SHOW_ANIMAL_NAMES": "If TRUE, displays animal names as text labels on the video frames. Useful for identifying which animal is which in multi-animal videos.",
  "ROI_TRACKING_NUMBER_OF_ANIMALS": "Number of animals to visualize. This determines how many body-part, color, and size dropdowns appear in the table below.",
  "ROI_TRACKING_BODY_PART": "Body-part to track for this animal's location within ROIs. Typically use center of mass (e.g., 'Center') or a prominent body-part like 'Nose'.",
  "ROI_TRACKING_BODY_PART_COLOR": "Color for this animal's body-part markers (circles). Choose a color that contrasts well with the video background and ROI colors.",
  "ROI_TRACKING_KEYPOINT_SIZE": "Size of the body-part marker circles in pixels. AUTO lets SimBA choose based on video size. Or set 1-100 pixels. Larger values are more visible but may obscure details.",
  "ROI_TRACKING_OUTSIDE_ROI": "If TRUE, treats all areas NOT covered by drawn ROIs as a single additional ROI named 'OUTSIDE REGIONS OF INTEREST'. Shows statistics for time spent outside all ROIs.",
  "ROI_TRACKING_CPU_CORES": "Number of CPU cores to use for processing. Higher values speed up processing for multiple videos but use more memory. Recommended: half of available cores.",
  "ROI_TRACKING_SINGLE_VIDEO": "Select which video to create ROI tracking visualization for. Only videos that have both ROI definitions and pose data are shown.",
  "ROI_TRACKING_PROBABILITY_THRESHOLD": "Minimum pose-estimation confidence threshold (0.0-1.0). Only frames where body-part detection confidence exceeds this value are used for ROI tracking. Lower values include more frames but may add noise. Higher values are stricter and filter out low-confidence detections.",
  "ROI_FEATURES_PROBABILITY_THRESHOLD": "Minimum pose-estimation confidence threshold (0.0-1.0). Body-part locations detected below this value are filtered out when visualizing ROI features. Lower values include more frames but may add noise.",
  "ROI_FEATURES_SHOW_DIRECTIONALITY": "If directionality data exists: FALSE = no direction overlay; LINES = show direction as lines; FUNNEL = show funnel-style direction. Disabled when directionality is not available for the project.",
  "ROI_FEATURES_SHOW_ROI_CENTERS": "If TRUE, displays a marker at the center of each ROI on the video frames. Helps identify which ROI is which.",
  "ROI_FEATURES_SHOW_ROI_EARTAGS": "If TRUE, displays ear-tag style labels on each ROI (e.g. ROI_1, ROI_2) on the video frames.",
  "ROI_FEATURES_SELECT_VIDEO": "Select which video to visualize ROI features for. Only videos that have ROI definitions are listed.",
  "ROI_AGGREGATE_PROBABILITY_THRESHOLD": "Minimum pose-estimation confidence threshold (0.0-1.0).\nOnly frames where body-part detection confidence exceeds this value are used for ROI aggregate statistics.\nLower values include more frames but may add noise. Higher values are stricter and filter out low-confidence detections.",
  "ROI_AGGREGATE_TOTAL_TIME": "If checked, calculates the total duration (in seconds) that each animal spends inside each ROI.\nSums all time periods where the selected body-part is located within the ROI boundaries.",
  "ROI_AGGREGATE_ENTRY_COUNTS": "If checked, counts how many times each animal enters each ROI.\nAn entry occurs when the animal moves from outside an ROI to inside it.",
  "ROI_AGGREGATE_FIRST_ENTRY_TIME": "If checked, calculates the time (in seconds) when each animal first enters each ROI.\nUseful for analyzing latency to reach specific regions.",
  "ROI_AGGREGATE_LAST_ENTRY_TIME": "If checked, calculates the time (in seconds) when each animal last enters each ROI.\nShows the final entry time before the video ends or the animal leaves permanently.",
  "ROI_AGGREGATE_MEAN_BOUT_TIME": "If checked, calculates the average duration (in seconds) of each ROI visit (bout).\nA bout is the time period from entering an ROI until leaving it.",
  "ROI_AGGREGATE_DETAILED_BOUT_DATA": "If checked, creates a detailed CSV table listing each individual ROI visit (bout).\nIncludes start time, end time, duration, ROI name, and animal identifier for every entry/exit sequence.",
  "ROI_AGGREGATE_MOVEMENT": "If checked, calculates movement metrics (velocity and distance traveled) within each ROI.\nMeasures how much and how fast the animal moves while inside each ROI region.",
  "ROI_AGGREGATE_OUTSIDE_ROI": "If checked, treats all areas NOT covered by drawn ROIs as a single additional ROI\nnamed 'OUTSIDE REGIONS OF INTEREST'. Shows statistics for time spent outside all defined ROIs.",
  "ROI_AGGREGATE_TRANSPOSE": "If checked, transposes the output table so each video is one row\nand ROI-animal-bodypart-measurement combinations are columns.\nDefault: each row is a video-ROI-animal-bodypart-measurement combination.",
  "ROI_AGGREGATE_INCLUDE_FPS": "If checked, includes the video frame rate (frames per second) as a metadata column in the output.\nUseful for converting frame-based measurements to time-based units.",
  "ROI_AGGREGATE_INCLUDE_VIDEO_LENGTH": "If checked, includes the video length in seconds as a metadata column in the output.\nProvides context for interpreting time-based measurements relative to total video duration.",
  "ROI_AGGREGATE_INCLUDE_PX_PER_MM": "If checked, includes the pixel-per-millimeter calibration value as a metadata column.\nThis value converts pixel distances to real-world measurements (millimeters) for each video.",
  "ROI_TIMEBINS_TIME_BIN_SIZE": "Duration of each time bin in seconds.\nThe video is divided into equal time segments of this length, and ROI statistics are calculated separately for each bin.\nFor example, 60 seconds creates 1-minute bins showing ROI metrics per minute.",
  "ROI_TIMEBINS_INCLUDE_TIMESTAMPS": "If checked, includes timestamp columns (HH:MM:SS format) showing the start and end time of each time bin.\nUseful for aligning ROI statistics with specific video time periods or other time-based analyses.",
  "ROI_TIMEBINS_TOTAL_TIME": "If checked, calculates the total duration (in seconds) that each animal spends inside each ROI for each time bin.\nSums all time periods where the selected body-part is located within the ROI boundaries during that bin.",
  "ROI_TIMEBINS_ENTRY_COUNTS": "If checked, counts how many times each animal enters each ROI within each time bin.\nAn entry occurs when the animal moves from outside an ROI to inside it during the bin period.",
  "ROI_TIMEBINS_FIRST_ENTRY_TIME": "If checked, calculates the time (in seconds) when each animal first enters each ROI within each time bin.\nUseful for analyzing latency to reach specific regions within time segments.",
  "ROI_TIMEBINS_LAST_ENTRY_TIME": "If checked, calculates the time (in seconds) when each animal last enters each ROI within each time bin.\nShows the final entry time within that bin period.",
  "ROI_TIMEBINS_DETAILED_BOUT_DATA": "If checked, creates a detailed CSV table listing each individual ROI visit (bout) within each time bin.\nIncludes start time, end time, duration, ROI name, animal identifier, and time bin for every entry/exit sequence.",
  "ROI_TIMEBINS_MOVEMENT": "If checked, calculates movement metrics (velocity and distance traveled) within each ROI for each time bin.\nMeasures how much and how fast the animal moves while inside each ROI region during that time segment.",
  "ROI_TIMEBINS_TRANSPOSE": "If checked, transposes the output table so each video is one row\nand time-bin-ROI-animal-bodypart-measurement combinations are columns.\nDefault: each row is a video-timebin-ROI-animal-bodypart-measurement combination.",
  "SMOOTH_TIME_WINDOW": "How much to smooth the tracks (in milliseconds). Bigger = smoother but less responsive. Try 100–300.",
  "SMOOTH_METHOD": "Gaussian = smooth and even. Savitzky-Golay = smooth but keeps sharp turns better. Both reduce wobbly tracks.",
  "SMOOTH_SAVE_ORIGINALS": "TRUE = keep a backup of your data before smoothing. FALSE = overwrite (no backup).",
  "SMOOTH_DATA_PATH": "Pick one pose data file (CSV or Parquet) to smooth. It must be in a folder under project_folder/csv.",
  "SMOOTH_DATA_DIR": "Pick a folder of pose files to smooth. Every file in that folder will be processed. Folder must be under project_folder/csv.",
  "INTERPOLATE_TYPE": "MISSING BODY-PARTS = fill in missing points per body-part. MISSING ANIMALS = fill in whole missing animals (all their points).",
  "INTERPOLATE_METHOD": "NEAREST = repeat nearest value. LINEAR = draw a straight line between gaps. QUADRATIC = smoother curve. Try NEAREST or LINEAR first.",
  "INTERPOLATE_SAVE_ORIGINALS": "TRUE = keep a backup before filling gaps. FALSE = overwrite (no backup).",
  "INTERPOLATE_DATA_PATH": "Pick one pose data file (CSV or Parquet) to fill gaps in. It must be in a folder under project_folder/csv.",
  "INTERPOLATE_DATA_DIR": "Pick a folder of pose files to fill gaps in. Every file in that folder will be processed. Folder must be under project_folder/csv.",
  "GANTT_RESOLUTION": "Size of the output image or video (width×height in pixels). Bigger = sharper but slower and larger files.",
  "GANTT_TEXT_SIZE": "How big the behavior names appear (1–25). Bigger = easier to read; too big can overlap if you have many behaviors.",
  "GANTT_TEXT_ROTATION": "Tilt of the behavior labels (0–180°). Use 90° for vertical text when you have lots of behaviors.",
  "GANTT_PALETTE": "Color scheme for the behavior bars. Set1 and similar give each behavior its own color.",
  "GANTT_TIME_FORMAT": "SECONDS = numbers (e.g. 120). HH:MM:SS = clock style (e.g. 00:02:00). Use HH:MM:SS for long videos or slides.",
  "GANTT_BAR_OPACITY": "How see-through the bars are (0.05–1). Lower = more transparent so overlapping bars are easier to tell apart.",
  "GANTT_CPU_CORES": "How many CPU cores to use when making several Gantt videos. More = faster, but don’t set higher than your computer has.",
  "GANTT_FONT": "Font for the behavior names. AUTO = SimBA picks one. Or choose a font you like.",
  "GANTT_SINGLE_VIDEO": "Which video’s classification results to turn into a Gantt. Only this one is used when you click the single-video button.",
  "GANTT_BEHAVIOR": "Tick to show this behavior on the Gantt chart. You need at least one. Each behavior gets its own row of colored bars.",
  "GANTT_CREATE_FRAMES": "Save one image per frame (many images). Use if you need to step through the video frame by frame.",
  "GANTT_CREATE_VIDEOS": "Save a video where the Gantt chart builds over time, frame by frame.",
  "GANTT_CREATE_LAST_FRAME": "Save one image with the full Gantt chart at the end of the video. Good for a quick summary (on by default).",
  "CLF_PLOT_BP_THRESHOLD": "Hide body-parts with confidence below this (0–1). 0 = show everything. Higher = hide shaky points.",
  "CLF_PLOT_TEXT_SIZE": "Size of the behavior labels on the video. AUTO = SimBA picks. Or choose 1–100.",
  "CLF_PLOT_TEXT_SPACING": "Space between the label text and other drawn elements. AUTO = SimBA picks.",
  "CLF_PLOT_TEXT_THICKNESS": "How bold the behavior labels are. Higher = thicker, more visible text.",
  "CLF_PLOT_CIRCLE_SIZE": "Size of the dots drawn at each body-part. AUTO = SimBA picks based on video size.",
  "CLF_PLOT_TEXT_OPACITY": "How see-through the labels are (0.1–1). Lower = more transparent.",
  "CLF_PLOT_TEXT_COLOR": "Color of the behavior name text on the video.",
  "CLF_PLOT_BG_COLOR": "Color of the box behind the text. Helps the label stand out on busy frames.",
  "CLF_PLOT_TRACKING_PALETTE": "Colors for the pose dots (one color per animal). Set1 gives each animal a different color.",
  "CLF_PLOT_CPU_CORES": "How many CPU cores to use when making several videos. More = faster.",
  "CLF_PLOT_USE_GPU": "Use the graphics card to speed up making videos. Only works if you have a compatible GPU.",
  "CLF_PLOT_GANTT": "NO GANTT = no bar chart. Static = one bar chart at the end (faster). Dynamic = bar chart updates every frame.",
  "CLF_PLOT_SINGLE_VIDEO": "Which video to draw classifications on. Only this one is used for “Create single video”.",
  "CLF_PLOT_VIDEO_PATH": "Click to pick a video file. It should be one that has classification results in project_folder/csv/machine_results.",
  "CLF_PLOT_CREATE_VIDEO": "Make a video with behavior labels (and optional pose/timer) drawn on each frame.",
  "CLF_PLOT_CREATE_FRAMES": "Save one image per frame with labels drawn on. You get many images instead of one video.",
  "CLF_PLOT_INCLUDE_TIMERS": "Show a timer (time or frame number) on each frame. Handy for talks or matching other data.",
  "CLF_PLOT_ROTATE_VIDEO": "Turn the output 90°. Use this if your video was recorded in portrait (vertical).",
  "CLF_PLOT_SHOW_POSE": "Draw the tracked body-parts (dots and skeleton) on the video so you see where the animal was detected.",
  "CLF_PLOT_SHOW_ANIMAL_NAMES": "Show labels like “Animal_1” on the video so you can tell animals apart.",
  "CLF_PLOT_SHOW_BBOX": "Draw a box around each animal. Helps see where the animal is and if animals overlap.",
  "CLF_PLOT_SHOW_PROBABILITY": "Show how confident the model was (0–100%) for the predicted behavior on each frame.",
  "CLF_PLOT_TIME_SEGMENT": "When enabled, only a portion of the video is visualized.\nSet START TIME and END TIME below to define the segment (format: HH:MM:SS).\nLeave disabled to process the entire video.",
  "CLF_PLOT_PLOT_SPECIFIC_TIME_SEGMENT": "If checked, only frames between START TIME and END TIME are drawn on the video.\nUseful to focus on a specific part (e.g. a 1‑minute trial) instead of the full video.",
  "CLF_PLOT_START_TIME": "When the plotted segment begins. Format: HH:MM:SS (e.g. 00:01:30 = 1 min 30 sec).\nOnly used when PLOT SPECIFIC TIME SEGMENT is checked.",
  "CLF_PLOT_END_TIME": "When the plotted segment ends. Format: HH:MM:SS. Must be after START TIME.\nOnly used when PLOT SPECIFIC TIME SEGMENT is checked.",
  "CREATE_PROJECT_DIR": "Folder where the new SimBA project will be created.\nAll project files (videos, CSV, config) will live inside a subfolder with the project name.",
  "CREATE_PROJECT_NAME": "Name for your project. SimBA will create a folder with this name inside the project directory.\nKeep it short; avoid spaces or special characters.",
  "CREATE_PROJECT_FILE_TYPE": "Format for saving pose and results (e.g. CSV or Parquet).\nCSV is strongly recommended.",
  "CREATE_PROJECT_TRACKING_TYPE": "Classic tracking = non-track-based (e.g. one animal or visually discriminable animals; no track IDs). Multi tracking = track-based multi-animal (e.g. DLC 2.2+, SLEAP; data has track/identity IDs). 3D tracking = 3D pose data.\nThis choice decides which body-part configurations appear in the dropdown below.",
  "CREATE_PROJECT_BP_CONFIG": "Which body-part set to use (e.g. 8 points, 14 points). Must match your tracking data or the data you plan to import.",
  "CREATE_PROJECT_RESET_POSE_CONFIGS": "Remove all user-defined pose configurations from this SimBA installation. Existing user-defined configs are archived before deletion so you can restore them later.",
  "IMPORT_VIDEOS_VIDEO_DIRECTORY": "Folder containing the video files to import. SimBA will copy (or symlink) all videos matching the selected file format from this folder into the project.",
  "IMPORT_VIDEOS_VIDEO_FILE_FORMAT": "File extension to match when importing multiple videos (e.g. .mp4, .avi). Only files with this extension in the selected directory will be imported.",
  "IMPORT_VIDEOS_VIDEO_PATH": "Path to a single video file to import into the project. Use BROWSE to pick the file; it will be copied or symlinked into the project's video folder.",
  "IMPORT_VIDEOS_IMPORT_SYMLINKS": "If checked, create symbolic links to the source videos instead of copying files. Saves disk space and keeps project in sync with the source; requires the source path to remain available.",
  "IMPORT_POSE_DATA_TYPE": "Source format of the pose data (e.g. DLC CSV, SLEAP, multi-animal DLC H5). This determines which file/folder selectors and options appear below.",
  "IMPORT_POSE_INTERPOLATION": "How to fill missing or low-confidence pose keypoints. Options include interpolation by animal(s) or body-parts, or None to leave gaps.",
  "IMPORT_POSE_SMOOTHING": "Temporal smoothing to reduce jitter in keypoint trajectories. Gaussian or Savitzky-Golay use the period (ms) below; None disables smoothing.",
  "IMPORT_POSE_SMOOTHING_PERIOD_MS": "Time window in milliseconds for smoothing (e.g. 100–300). Only used when a smoothing method other than None is selected.",
  "IMPORT_POSE_INPUT_DATA_DIRECTORY": "Folder containing pose files to import (e.g. DLC CSV, DANNCE MAT, BENTO JSON, SimBA BLOB, FaceMap H5, or YOLO CSV). All matching files in the folder will be imported.",
  "IMPORT_POSE_INPUT_DATA_FILE": "Path to a single pose file to import. Use BROWSE to select one file; format must match the selected DATA TYPE.",
  "IMPORT_POSE_ANIMAL_COUNT": "Number of animals in the tracking data. Used for multi-animal formats (DLC H5, SLEAP, APT TRK, etc.) to create the correct number of animal name fields.",
  "IMPORT_POSE_ANIMAL_NAME": "Name or ID for this animal (e.g. Animal_1, mouse_A). Must match how your tracking tool labels individuals; used for multi-animal imports.",
  "IMPORT_POSE_DLC_TRACKING_TYPE": "Multi-animal DLC export format. Choose the file type that matches your exported DLC data (e.g. h5, csv).",
  "IMPORT_POSE_MULTI_ANIMAL_DATA_DIRECTORY": "Folder containing multi-animal pose files (DLC H5, SLEAP SLP/CSV/H5, APT TRK, or SuperAnimal H5). File names should match project videos.",
  "LOAD_PROJECT_CONFIG_FILE": "Path to the project_config.ini file of the SimBA project you want to open. Use BROWSE to select the file; it is usually inside the project folder.",
  "LOAD_PROJECT_RECENT_CONFIG": "Previously loaded projects. Select one from the list and click LOAD RECENT PROJECT to open it without browsing.",
  "BG_REMOVE_VIDEO_PATH": "The video file to process. SimBA compares each frame to a learned background and replaces background pixels with your chosen color. The output video is saved in the same folder with a new filename.",
  "BG_REMOVE_BG_REFERENCE_VIDEO_PATH": "Optional. A different video whose frames are averaged to estimate the background. Leave blank to use the input video itself. Use a separate reference when the animal is almost always moving (e.g., cage footage) and the input video has no clear empty background—provide a similar video where the cage/enclosure is empty or the animal is out of frame.",
  "BG_REMOVE_BACKGROUND_COLOR": "The color that replaces the background (everything not detected as the animal). SimBA averages frames to build a background model, then paints pixels that match that background with this color. Pick a color that contrasts with the foreground so the animal is easy to see.",
  "BG_REMOVE_FOREGROUND_COLOR": "The color of the animal (foreground) in the output. Original keeps the animal's real colors from the video. A solid color (e.g., black) gives a silhouette-style output useful for blob tracking or masking.",
  "BG_REMOVE_BACKGROUND_THRESHOLD": "Controls how different a pixel must be from the background to count as part of the animal (1–99). Low values (e.g., 10–20): more pixels count as animal, including shadows and subtle changes. High values (e.g., 50–80): only strong differences count. Start around 30 and adjust based on lighting and animal contrast.",
  "BG_REMOVE_BG_START": "Start of the segment used to build the background. Enter a frame number (e.g., 100) or time in HH:MM:SS. SimBA averages frames in this range. Use this when only part of the video has a usable empty background (e.g., the animal enters after a few seconds). Disabled when \"Compute background from entire video\" is checked.",
  "BG_REMOVE_BG_END": "End of the segment used to build the background. Must be after START. Enter a frame number or time in HH:MM:SS. Together with START, defines the window of frames averaged into the background model. Disabled when \"Compute background from entire video\" is checked.",
  "BG_REMOVE_CPU_CORE_COUNT": "How many CPU cores to use for parallel processing. More cores can make processing faster for long videos. Using more than half of your available cores may slow other programs or cause heavy CPU load.",
  "BG_REMOVE_ENTIRE_VIDEO_AS_BG": "If checked, SimBA averages the entire video (or reference video) to build the background. If unchecked, only the segment between BACKGROUND VIDEO START and END is used. Uncheck when the animal occupies the frame for most of the video—use START/END to pick a short period where the background is visible (e.g., before the animal enters).",
  "RUN_ML_CLASSIFIER_HEADER": "Names of the behavior classifiers defined in your project. Each row is one classifier you can run predictions for.",
  "RUN_ML_MODEL_PATH_HEADER": "Path to the trained model file (.sav). Pick the model you exported after training each classifier. Use BROWSE to select the file.",
  "RUN_ML_THRESHOLD_HEADER": "Classification threshold (0.0–1.0). Predictions below this are rejected. Higher values (e.g., 0.5–0.9) = stricter; lower = more permissive. Typical range: 0.3–0.7.",
  "RUN_ML_MIN_BOUT_HEADER": "Minimum bout length in milliseconds. Predictions shorter than this are filtered out. Reduces brief false positives; use 0 to keep all predictions.",
  "RUN_ML_CLASSIFIER_NAME": "Name of this behavior classifier as defined in the project. Set the model path, threshold, and minimum bout length for this classifier in the same row."
}